{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.datasets import CIFAR10\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "xy-yUE5cdNHu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Load the CIFAR-10 training dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "data = train_dataset.data\n",
        "\n",
        "data = data / 255.0\n",
        "\n",
        "mean = np.mean(data, axis=(0, 1, 2))\n",
        "\n",
        "std = np.std(data, axis=(0, 1, 2))\n",
        "\n",
        "# Print the results\n",
        "print(f\"Calculated Mean: {mean}\")\n",
        "print(f\"Calculated Std Dev: {std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZGq4f_qeDrD",
        "outputId": "d89a4a79-82f3-4ffe-ad9d-4519412c33b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated Mean: [0.49139968 0.48215841 0.44653091]\n",
            "Calculated Std Dev: [0.24703223 0.24348513 0.26158784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.1),\n",
        "    A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, min_height=16, min_width=16, fill_value=mean, mask_fill_value=None, p=0.1),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "class AlbumentationDataset(CIFAR10):\n",
        "    def __init__(self, root=\"./data\", train=True, download=True, transform=None):\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_dataset = AlbumentationDataset(root='./data', train=True, download=True, transform=train_transforms)\n",
        "test_dataset = AlbumentationDataset(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixZnLaGmdVc0",
        "outputId": "1ca725b0-5a5f-4577-917a-692ab386c1bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-1763199312.py:7: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, min_height=16, min_width=16, fill_value=mean, mask_fill_value=None, p=0.1),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2\n",
        "\n",
        "# CUDA?\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"GPU Available?\", device)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=128)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, **dataloader_args)\n",
        "\n",
        "# Pretty table for collecting all the accuracy and loss parameters in a table\n",
        "log_table = PrettyTable()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvUpXbBnd1H9",
        "outputId": "d9026b93-9680-4a9d-a2a3-9979d11445b1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available? cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P74Ed01iXvZi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "DROPOUT_PROB = 0.1\n",
        "\n",
        "class CIFAR10Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10Net, self).__init__()\n",
        "\n",
        "        # BLOCK 1\n",
        "        # Input: 32x32x3 | Output: 32x32x32 | RF: 5\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(DROPOUT_PROB),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(DROPOUT_PROB)\n",
        "        )\n",
        "\n",
        "        # BLOCK 2\n",
        "        # Input: 32x32x32 | Output: 16x16x32 | RF: 7\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(32)\n",
        "        )\n",
        "\n",
        "        # BLOCK 3\n",
        "        # Input: 16x16x32 | Output: 16x16x64 | RF: 31\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            # Depthwise Separable Convolution\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1, groups=32, bias=False), # Depthwise\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, bias=False), # Pointwise\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(DROPOUT_PROB),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=2, dilation=2, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(DROPOUT_PROB),\n",
        "        )\n",
        "\n",
        "        # BLOCK 4\n",
        "        # Input: 16x16x64 | Output: 8x8x128 | RF: 39\n",
        "        self.conv_block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        # Input: 8x8x128 | Output: 1x1x10 | RF: 55\n",
        "        self.output_block = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), # GAP layer\n",
        "            nn.Conv2d(in_channels=128, out_channels=10, kernel_size=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.output_block(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "cuda = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(cuda)\n",
        "model = CIFAR10Net().to(cuda)\n",
        "summary(model, input_size=(3, 32, 32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dTETUUEdFnx",
        "outputId": "4e25a3f0-c48a-4c2f-aac7-0b064111e92c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "           Dropout-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           4,608\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
            "           Dropout-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]           9,216\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-11           [-1, 32, 16, 16]              64\n",
            "           Conv2d-12           [-1, 32, 16, 16]             288\n",
            "           Conv2d-13           [-1, 64, 16, 16]           2,048\n",
            "             ReLU-14           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-15           [-1, 64, 16, 16]             128\n",
            "          Dropout-16           [-1, 64, 16, 16]               0\n",
            "           Conv2d-17           [-1, 64, 16, 16]          36,864\n",
            "             ReLU-18           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-19           [-1, 64, 16, 16]             128\n",
            "          Dropout-20           [-1, 64, 16, 16]               0\n",
            "           Conv2d-21            [-1, 128, 8, 8]          73,728\n",
            "             ReLU-22            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
            "AdaptiveAvgPool2d-24            [-1, 128, 1, 1]               0\n",
            "           Conv2d-25             [-1, 10, 1, 1]           1,280\n",
            "================================================================\n",
            "Total params: 129,136\n",
            "Trainable params: 129,136\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.94\n",
            "Params size (MB): 0.49\n",
            "Estimated Total Size (MB): 3.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(y_pred, target)\n",
        "    #loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n"
      ],
      "metadata": {
        "id": "bRekbxy6ecbj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "from prettytable import PrettyTable, MSWORD_FRIENDLY, MARKDOWN\n",
        "\n",
        "print(\"model running on: \", device)\n",
        "log_table = PrettyTable()\n",
        "log_table.field_names = [\"Epoch\", \"Training Accuracy\", \"Test Accuracy\", \"Diff\", \"Training Loss\", \"Test Loss\"]\n",
        "\n",
        "model =  CIFAR10Net().to(device)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch+1)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    #scheduler.step()\n",
        "    test(model, device, test_loader)\n",
        "    log_table.add_row([epoch+1, f\"{train_acc[-1]:.2f}%\", f\"{test_acc[-1]:.2f}%\", f\"{float(train_acc[-1]) - float(test_acc[-1]):.2f}\" ,f\"{train_losses[-1]:.4f}\", f\"{test_losses[-1]:.4f}\"])\n",
        "log_table.set_style(MARKDOWN)\n",
        "print(log_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb0D7A1VefQz",
        "outputId": "2f595ef4-c165-4878-8aa4-c13f2203e85f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1556196367.py:2: DeprecationWarning: the 'MSWORD_FRIENDLY' constant is deprecated, use the 'TableStyle' enum instead\n",
            "  from prettytable import PrettyTable, MSWORD_FRIENDLY, MARKDOWN\n",
            "/tmp/ipython-input-1556196367.py:2: DeprecationWarning: the 'MARKDOWN' constant is deprecated, use the 'TableStyle' enum instead\n",
            "  from prettytable import PrettyTable, MSWORD_FRIENDLY, MARKDOWN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model running on:  cuda\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.223803162574768 Batch_id=390 Accuracy=49.58: 100%|██████████| 391/391 [00:10<00:00, 35.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0870, Accuracy: 6057/10000 (60.57%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9151042699813843 Batch_id=390 Accuracy=64.34: 100%|██████████| 391/391 [00:10<00:00, 38.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9155, Accuracy: 6800/10000 (68.00%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9748958349227905 Batch_id=390 Accuracy=70.18: 100%|██████████| 391/391 [00:09<00:00, 39.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7707, Accuracy: 7281/10000 (72.81%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7730000019073486 Batch_id=390 Accuracy=73.57: 100%|██████████| 391/391 [00:09<00:00, 39.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7294, Accuracy: 7477/10000 (74.77%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5815104246139526 Batch_id=390 Accuracy=76.14: 100%|██████████| 391/391 [00:10<00:00, 38.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6831, Accuracy: 7625/10000 (76.25%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8225975036621094 Batch_id=390 Accuracy=77.98: 100%|██████████| 391/391 [00:10<00:00, 36.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6047, Accuracy: 7890/10000 (78.90%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7528146505355835 Batch_id=390 Accuracy=79.31: 100%|██████████| 391/391 [00:10<00:00, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5960, Accuracy: 7940/10000 (79.40%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6128249168395996 Batch_id=390 Accuracy=80.24: 100%|██████████| 391/391 [00:10<00:00, 36.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5838, Accuracy: 7988/10000 (79.88%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6028963923454285 Batch_id=390 Accuracy=81.17: 100%|██████████| 391/391 [00:10<00:00, 37.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5375, Accuracy: 8129/10000 (81.29%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.39518359303474426 Batch_id=390 Accuracy=81.67: 100%|██████████| 391/391 [00:10<00:00, 37.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5178, Accuracy: 8205/10000 (82.05%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5978726744651794 Batch_id=390 Accuracy=82.56: 100%|██████████| 391/391 [00:10<00:00, 36.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5259, Accuracy: 8210/10000 (82.10%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.35919463634490967 Batch_id=390 Accuracy=82.93: 100%|██████████| 391/391 [00:10<00:00, 38.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5172, Accuracy: 8242/10000 (82.42%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5130105018615723 Batch_id=390 Accuracy=83.33: 100%|██████████| 391/391 [00:09<00:00, 41.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5061, Accuracy: 8281/10000 (82.81%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6213909983634949 Batch_id=390 Accuracy=83.77: 100%|██████████| 391/391 [00:09<00:00, 39.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4939, Accuracy: 8323/10000 (83.23%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5182145833969116 Batch_id=390 Accuracy=84.30: 100%|██████████| 391/391 [00:11<00:00, 34.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4951, Accuracy: 8326/10000 (83.26%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.39655908942222595 Batch_id=390 Accuracy=84.60: 100%|██████████| 391/391 [00:10<00:00, 37.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5275, Accuracy: 8251/10000 (82.51%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.38757190108299255 Batch_id=390 Accuracy=84.96: 100%|██████████| 391/391 [00:10<00:00, 37.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4907, Accuracy: 8337/10000 (83.37%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4423726201057434 Batch_id=390 Accuracy=85.35: 100%|██████████| 391/391 [00:10<00:00, 37.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5149, Accuracy: 8290/10000 (82.90%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.41987913846969604 Batch_id=390 Accuracy=85.49: 100%|██████████| 391/391 [00:10<00:00, 36.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5059, Accuracy: 8301/10000 (83.01%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.39618009328842163 Batch_id=390 Accuracy=85.84: 100%|██████████| 391/391 [00:10<00:00, 37.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4948, Accuracy: 8393/10000 (83.93%)\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3927505910396576 Batch_id=390 Accuracy=86.06: 100%|██████████| 391/391 [00:10<00:00, 38.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4611, Accuracy: 8432/10000 (84.32%)\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5805143117904663 Batch_id=390 Accuracy=86.19: 100%|██████████| 391/391 [00:09<00:00, 40.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4875, Accuracy: 8366/10000 (83.66%)\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4517667293548584 Batch_id=390 Accuracy=86.54: 100%|██████████| 391/391 [00:09<00:00, 41.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4880, Accuracy: 8353/10000 (83.53%)\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.25974878668785095 Batch_id=390 Accuracy=86.57: 100%|██████████| 391/391 [00:10<00:00, 38.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4722, Accuracy: 8426/10000 (84.26%)\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.35850661993026733 Batch_id=390 Accuracy=87.00: 100%|██████████| 391/391 [00:10<00:00, 37.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4892, Accuracy: 8410/10000 (84.10%)\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.21230335533618927 Batch_id=390 Accuracy=87.38: 100%|██████████| 391/391 [00:10<00:00, 37.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4682, Accuracy: 8443/10000 (84.43%)\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6947134137153625 Batch_id=390 Accuracy=87.15: 100%|██████████| 391/391 [00:10<00:00, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4675, Accuracy: 8446/10000 (84.46%)\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4665605425834656 Batch_id=390 Accuracy=87.43: 100%|██████████| 391/391 [00:10<00:00, 37.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4910, Accuracy: 8390/10000 (83.90%)\n",
            "\n",
            "EPOCH: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.29158759117126465 Batch_id=390 Accuracy=87.71: 100%|██████████| 391/391 [00:10<00:00, 37.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4846, Accuracy: 8465/10000 (84.65%)\n",
            "\n",
            "EPOCH: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.41242653131484985 Batch_id=390 Accuracy=87.79: 100%|██████████| 391/391 [00:09<00:00, 40.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4545, Accuracy: 8496/10000 (84.96%)\n",
            "\n",
            "EPOCH: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.680749773979187 Batch_id=390 Accuracy=88.04: 100%|██████████| 391/391 [00:09<00:00, 41.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4524, Accuracy: 8498/10000 (84.98%)\n",
            "\n",
            "EPOCH: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.31119805574417114 Batch_id=390 Accuracy=88.19: 100%|██████████| 391/391 [00:10<00:00, 37.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4653, Accuracy: 8451/10000 (84.51%)\n",
            "\n",
            "EPOCH: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.41903629899024963 Batch_id=390 Accuracy=88.15: 100%|██████████| 391/391 [00:10<00:00, 37.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4791, Accuracy: 8454/10000 (84.54%)\n",
            "\n",
            "EPOCH: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.2843922972679138 Batch_id=390 Accuracy=88.12: 100%|██████████| 391/391 [00:10<00:00, 37.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4733, Accuracy: 8434/10000 (84.34%)\n",
            "\n",
            "EPOCH: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5898496508598328 Batch_id=390 Accuracy=88.57: 100%|██████████| 391/391 [00:10<00:00, 37.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4586, Accuracy: 8519/10000 (85.19%)\n",
            "\n",
            "EPOCH: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.37316054105758667 Batch_id=390 Accuracy=88.56: 100%|██████████| 391/391 [00:10<00:00, 37.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4617, Accuracy: 8454/10000 (84.54%)\n",
            "\n",
            "EPOCH: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4005200266838074 Batch_id=390 Accuracy=88.73: 100%|██████████| 391/391 [00:09<00:00, 39.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4684, Accuracy: 8465/10000 (84.65%)\n",
            "\n",
            "EPOCH: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4067765772342682 Batch_id=390 Accuracy=88.92: 100%|██████████| 391/391 [00:09<00:00, 41.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4705, Accuracy: 8460/10000 (84.60%)\n",
            "\n",
            "EPOCH: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3579431474208832 Batch_id=390 Accuracy=88.95: 100%|██████████| 391/391 [00:09<00:00, 40.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4563, Accuracy: 8525/10000 (85.25%)\n",
            "\n",
            "EPOCH: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3399641513824463 Batch_id=390 Accuracy=88.97: 100%|██████████| 391/391 [00:10<00:00, 37.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4537, Accuracy: 8530/10000 (85.30%)\n",
            "\n",
            "EPOCH: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.23141101002693176 Batch_id=390 Accuracy=89.03: 100%|██████████| 391/391 [00:11<00:00, 34.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4453, Accuracy: 8561/10000 (85.61%)\n",
            "\n",
            "EPOCH: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4962076246738434 Batch_id=390 Accuracy=89.54: 100%|██████████| 391/391 [00:10<00:00, 37.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4596, Accuracy: 8525/10000 (85.25%)\n",
            "\n",
            "EPOCH: 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3248372972011566 Batch_id=390 Accuracy=89.08: 100%|██████████| 391/391 [00:10<00:00, 36.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4859, Accuracy: 8424/10000 (84.24%)\n",
            "\n",
            "EPOCH: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3755224347114563 Batch_id=390 Accuracy=89.52: 100%|██████████| 391/391 [00:10<00:00, 37.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4852, Accuracy: 8482/10000 (84.82%)\n",
            "\n",
            "EPOCH: 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3703649342060089 Batch_id=390 Accuracy=89.61: 100%|██████████| 391/391 [00:09<00:00, 39.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4560, Accuracy: 8540/10000 (85.40%)\n",
            "\n",
            "EPOCH: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.25547662377357483 Batch_id=390 Accuracy=89.44: 100%|██████████| 391/391 [00:09<00:00, 41.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4606, Accuracy: 8487/10000 (84.87%)\n",
            "\n",
            "EPOCH: 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.2557060122489929 Batch_id=390 Accuracy=89.75: 100%|██████████| 391/391 [00:09<00:00, 39.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4732, Accuracy: 8469/10000 (84.69%)\n",
            "\n",
            "EPOCH: 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3020472824573517 Batch_id=390 Accuracy=89.71: 100%|██████████| 391/391 [00:10<00:00, 36.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4761, Accuracy: 8478/10000 (84.78%)\n",
            "\n",
            "EPOCH: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3766241669654846 Batch_id=390 Accuracy=89.77: 100%|██████████| 391/391 [00:10<00:00, 37.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4630, Accuracy: 8540/10000 (85.40%)\n",
            "\n",
            "EPOCH: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.41594618558883667 Batch_id=390 Accuracy=90.05: 100%|██████████| 391/391 [00:10<00:00, 35.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4559, Accuracy: 8538/10000 (85.38%)\n",
            "\n",
            "| Epoch | Training Accuracy | Test Accuracy |  Diff  | Training Loss | Test Loss |\n",
            "| :---: | :---------------: | :-----------: | :----: | :-----------: | :-------: |\n",
            "|   1   |       49.58%      |     60.57%    | -10.99 |     1.2238    |   1.0870  |\n",
            "|   2   |       64.34%      |     68.00%    | -3.66  |     0.9151    |   0.9155  |\n",
            "|   3   |       70.18%      |     72.81%    | -2.63  |     0.9749    |   0.7707  |\n",
            "|   4   |       73.57%      |     74.77%    | -1.20  |     0.7730    |   0.7294  |\n",
            "|   5   |       76.14%      |     76.25%    | -0.11  |     0.5815    |   0.6831  |\n",
            "|   6   |       77.98%      |     78.90%    | -0.92  |     0.8226    |   0.6047  |\n",
            "|   7   |       79.31%      |     79.40%    | -0.09  |     0.7528    |   0.5960  |\n",
            "|   8   |       80.24%      |     79.88%    |  0.36  |     0.6128    |   0.5838  |\n",
            "|   9   |       81.17%      |     81.29%    | -0.12  |     0.6029    |   0.5375  |\n",
            "|   10  |       81.67%      |     82.05%    | -0.38  |     0.3952    |   0.5178  |\n",
            "|   11  |       82.56%      |     82.10%    |  0.46  |     0.5979    |   0.5259  |\n",
            "|   12  |       82.93%      |     82.42%    |  0.51  |     0.3592    |   0.5172  |\n",
            "|   13  |       83.33%      |     82.81%    |  0.52  |     0.5130    |   0.5061  |\n",
            "|   14  |       83.77%      |     83.23%    |  0.54  |     0.6214    |   0.4939  |\n",
            "|   15  |       84.30%      |     83.26%    |  1.04  |     0.5182    |   0.4951  |\n",
            "|   16  |       84.60%      |     82.51%    |  2.09  |     0.3966    |   0.5275  |\n",
            "|   17  |       84.96%      |     83.37%    |  1.59  |     0.3876    |   0.4907  |\n",
            "|   18  |       85.35%      |     82.90%    |  2.45  |     0.4424    |   0.5149  |\n",
            "|   19  |       85.49%      |     83.01%    |  2.48  |     0.4199    |   0.5059  |\n",
            "|   20  |       85.84%      |     83.93%    |  1.91  |     0.3962    |   0.4948  |\n",
            "|   21  |       86.06%      |     84.32%    |  1.74  |     0.3928    |   0.4611  |\n",
            "|   22  |       86.19%      |     83.66%    |  2.53  |     0.5805    |   0.4875  |\n",
            "|   23  |       86.54%      |     83.53%    |  3.01  |     0.4518    |   0.4880  |\n",
            "|   24  |       86.57%      |     84.26%    |  2.31  |     0.2597    |   0.4722  |\n",
            "|   25  |       87.00%      |     84.10%    |  2.90  |     0.3585    |   0.4892  |\n",
            "|   26  |       87.38%      |     84.43%    |  2.95  |     0.2123    |   0.4682  |\n",
            "|   27  |       87.15%      |     84.46%    |  2.69  |     0.6947    |   0.4675  |\n",
            "|   28  |       87.43%      |     83.90%    |  3.53  |     0.4666    |   0.4910  |\n",
            "|   29  |       87.71%      |     84.65%    |  3.06  |     0.2916    |   0.4846  |\n",
            "|   30  |       87.79%      |     84.96%    |  2.83  |     0.4124    |   0.4545  |\n",
            "|   31  |       88.04%      |     84.98%    |  3.06  |     0.6807    |   0.4524  |\n",
            "|   32  |       88.19%      |     84.51%    |  3.68  |     0.3112    |   0.4653  |\n",
            "|   33  |       88.15%      |     84.54%    |  3.61  |     0.4190    |   0.4791  |\n",
            "|   34  |       88.12%      |     84.34%    |  3.78  |     0.2844    |   0.4733  |\n",
            "|   35  |       88.57%      |     85.19%    |  3.38  |     0.5898    |   0.4586  |\n",
            "|   36  |       88.56%      |     84.54%    |  4.02  |     0.3732    |   0.4617  |\n",
            "|   37  |       88.73%      |     84.65%    |  4.08  |     0.4005    |   0.4684  |\n",
            "|   38  |       88.92%      |     84.60%    |  4.32  |     0.4068    |   0.4705  |\n",
            "|   39  |       88.95%      |     85.25%    |  3.70  |     0.3579    |   0.4563  |\n",
            "|   40  |       88.97%      |     85.30%    |  3.67  |     0.3400    |   0.4537  |\n",
            "|   41  |       89.03%      |     85.61%    |  3.42  |     0.2314    |   0.4453  |\n",
            "|   42  |       89.54%      |     85.25%    |  4.29  |     0.4962    |   0.4596  |\n",
            "|   43  |       89.08%      |     84.24%    |  4.84  |     0.3248    |   0.4859  |\n",
            "|   44  |       89.52%      |     84.82%    |  4.70  |     0.3755    |   0.4852  |\n",
            "|   45  |       89.61%      |     85.40%    |  4.21  |     0.3704    |   0.4560  |\n",
            "|   46  |       89.44%      |     84.87%    |  4.57  |     0.2555    |   0.4606  |\n",
            "|   47  |       89.75%      |     84.69%    |  5.06  |     0.2557    |   0.4732  |\n",
            "|   48  |       89.71%      |     84.78%    |  4.93  |     0.3020    |   0.4761  |\n",
            "|   49  |       89.77%      |     85.40%    |  4.37  |     0.3766    |   0.4630  |\n",
            "|   50  |       90.05%      |     85.38%    |  4.67  |     0.4159    |   0.4559  |\n"
          ]
        }
      ]
    }
  ]
}